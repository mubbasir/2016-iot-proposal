Given the interdisciplinary nature of the tasks in the proposed project, it is necessary to have well-defined mechanisms for assessing the validity and benefits of our findings. We will base our demonstration on variations of the two methodologically interdependent scenarios used in the introductory section.  We now discuss both the broad categories of evaluation environments, and the details of the particular evaluation methodologies. 
We will adopt a three-fold analysis of the different aspects of our system: (1) agent-based computer simulations, (2) experiments with real humans controlling avatars in shared virtual worlds, and (3) experiments with real humans in actual real-life environments. Each of these experimental paradigms allow us stress our system along a combination of the following three axes: (1) human stress, (2) replicating the noise inherent in using humans as sensors, and (3) scalability ? i.e., the number of participants (humans or agents). Agent-based simulations harness computation to simulate high-stress events in arbitrarily large crowds of computer agents, but are unable to accurately model humans. Shared online virtual worlds provide a unique opportunity to conduct experiments with real humans in controlled settings. While experiments with human subjects in the real world offer the closest possible parallel to reality, these experiments are limited in number of subjects and the extent of stress that we can induce on the participants. However, by leveraging combinations of all 3 paradigms, we are uniquely positioned to evaluate our models and technologies in a rigorous manner. 


\begin{wrapfigure}{R}{0.30\textwidth} \vspace{-3mm}
	\centerline{\includegraphics[width=0.30\textwidth]{evaluation-plan.png}}
	\vspace{-3mm} \caption{\small Evaluation using Agent simulations, Shared Online Virtual Worlds, and Real World Experiments.}
	\label{fig1}
	\vspace{-3mm}
\end{wrapfigure}

\subsubsection{Simulation-based Evaluations: Agents. }

The first part of our efforts will focus on developing simulator for the two demonstration settings. Throughout the different phases of the project we will be capitalizing upon ? as well as augmenting the current capabilities of ? the SIDnet SWANS simulator [195] and SteerSuite: The Human Movement and Crowd Simulator [196], being developed at Northwestern and Rutgers respectively. SIDnet is used to evaluate various routing and tracking protocols, shapes detection, and even to evaluate the benefits of high-level programming constructs for WSN-users [113, 160, 187, 191]. SteerSuite is an open-source framework for simulating human movement, deliberation, and is especially geared towards dense crowd situations. We will integrate the functionality of these two systems and further augment them with the capability of having heterogeneous nodes and capturing various mobility models and communications between subsets of such nodes. In addition, we will augment its visualization component as well as introduce a new class of nodes with the proper interfaces to encode the following important features: (1) camera/video/audio based sensing and (2) human and human-operated sensors.  For the multimodal mashup scenario, we will simulate a simplified version of the ?Gold Miner? using computer imagery, with virtual objects and sensors. 
The main use of the simulator in the initial stages of the proposal will be to test the various impacts of uncertainty (sensors, network structure/communication) on the quality of detecting the novel categories of spatio-temporal predicates (cf. Section 3.4) and the impact of different policies for local state-estimation and information extraction (cf. Section 3.1 and 3.3). We will employ a large variety of crowd datasets to train and validate our computational models, and in particular leverage our collaboration with Prof. Dirk Helbing who has significant expertise in crowd data collection, analysis, and modeling [197].  In particular, we will integrate our simulation infrastructure with the NervousNet platform [198] that is being actively developed by Prof. Helbing and his colleagues as part of the larger effort on the Planetary Nervous System project [199], which provides a large-scale distributed research platform for real-time mining of social activities using heterogeneous sensor networks.


\subsubsection{Task E-2. Game Playing Evaluation: Avatars. }

Agent-based simulations, such as those described above provide an efficient way to test and evaluate the different aspects of our system in an automated fashion. However, in an effort to come closer to actual human experimentation, we will conduct experiments using real human users in shared online virtual environments. The Rutgers team is uniquely positioned to conduct these experiments ? Co-PI Kapadia has developed HeapCraft [200, 2001]: a modular, extensible, and open framework for studying human behavior in shared virtual worlds such as Minecraft. HeapCraft has already been successfully demonstrated to study player behavior and incentivize cooperation in online societies [202, 203]. Additionally, Kapadia and his collaborators have also conducted lab experiments to study crowd evacuations using serious games.
We will augment the existing HeapCraft framework to design the two scenarios described in Task E-3 below. HeapCraft?s modular and extensible nature allows us to easily develop emulators for the technologies being developed here, which can be rigorously and robustly tested in shared virtual worlds using real human users. In addition, we will augment the knowledge-base for emulating behavioral aspects of the avatars using large datasets of preferences and semantic relations from real social networks obtained from 4C Insights Inc. (Letter of Commitment is available in the Supplementary Documents). 
Our experiments will be conducted in two phases: (I) laboratory studies where up to 40 participants will be recruited to participate in a controlled experiment; (II) online server with our tools released to setup a virtual world with hundreds of human-users  expected to participate. 


\subsubsection{Task E-3. Real-World Environment Evaluations.  }

The system we intend to develop is intrinsically oriented to be open source. It will need obviously the contribution of community members to feed, more or less automatically, the database of avatars in the social network of things. It also relies on a proactive contribution of users to improve the rules generator services. Rules generator, indeed, should not be a static repository of rules. Rather, it is a module which dynamically generates and improves rules at runtime. The way to accomplish these tasks, i.e., the software to do it, is based on well assessed algorithms. Nevertheless, it should be also open to improvements by the users. As common practice in open source communities, a third party serves as the booster of the software and the filter of contributions from users. We expect also that manufacturers and retailers will be highly motivated to foster this software so as to maintain the performance of their apparatuses at the high end of the market, with economic consequences. Users, meanwhile, are naturally inclined to communicate their best practices and analysis. They can do so at two levels: (1) just by issuing rules/instructions in a highly simplified script language involving both experience and their logical capabilities of formalizing it in a few well-formed expressions, and (2) by more sophisticated interventions on the open source codes, profiting their high level software experience and their knowledge of cognitive disciplines.\\
The primers of this community will be represented by two kinds of experiments respectively realizing small scale and large scale assets of our system.\\

\textbf{Small scale:}
A mock-up of the system will be physically realized in the lab of one of the partners (IIT?) with virtual extension to the other partners’ labs. Namely the former will consist of:

\begin{itemize}
	\item a set of 4 to 6 household appliances/IoTs connected to a middleware fog.
	\item a middleware fog hosted by a gateway that is connected to Internet.
	\item a social network instance hosted by a local server.
\end{itemize}

Equally relevant features validating the system will be:

(1) its reliability and recovery procedures w.r.t. any kind of inconvenience, ranging from power breakdown to loss of the Internet connection, or even hostile attack from an insider/outsider. The mock-up will also constitute a ground truth reference for the second class of experiments.\\
(2) its manageability on the part of the ordinary people, both in terms of realizing a middleware fog and connecting IoTs/appliances to it, and in terms of efficiently ruling the appliances/IoTs.\\

As for the last aspect, the cognitive capabilities of the networked intelligence will be dynamically improved as the entire project evolves.\\

This mock-up will constitute a continual ground truth reference for the second type of experiments.\\


\textbf{Large scale:}
Due to the great computational effort and massive statistics database required, this social community can survive only if attracts a huge number of members. Therefore, a main task of this project is to promote the functionalities of our infrastructure within the research community. In particular we plan to implement a cluster grouping from 1,000 to 10,000 domestic gateways (middleware fogs). Basing our dimensioning on the lower bound, the cluster should manage a total of 1,000,000 nodes. Many of the middleware functionalities are implemented locally on gateways (fogs). However, most of them needs frequent connections to the social networks of things, for instance to consult catalogues, reference instructions, tuning parameters, etc. We plan to attribute 2 GB of memory mass to each middleware – which is comparable with normal memory supply of smartphones and other smart personal appliances – for a total of 2 Terabytes. Moreover, given the scarce criticality of the ruled functions, we assume the clock stroke to be of the order of 1 second, and we prepare our software to manage a flow of 5,000 requests per second. These requests should be handled through 50 parallel processes entailing 25 GB RAM. As for the social network we plan to use 10 servers with 50GB RAM and 1TB memory for managing their operations in a modular and scalable way.


