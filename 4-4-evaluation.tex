Given the interdisciplinary nature of the tasks in the proposed project, it is necessary to have well-defined mechanisms for assessing the validity and benefits of our findings. We will base our demonstration on variations of the two methodologically interdependent scenarios used in the introductory section.  We now discuss both the broad categories of evaluation environments, and the details of the particular evaluation methodologies. 
We will adopt a three-fold analysis of the different aspects of our system: (1) agent-based computer simulations, (2) experiments with real humans controlling avatars in shared virtual worlds, and (3) experiments with real humans in actual real-life environments. Each of these experimental paradigms allow us stress our system along a combination of the following three axes: (1) human stress, (2) replicating the noise inherent in using humans as sensors, and (3) scalability ? i.e., the number of participants (humans or agents). Agent-based simulations harness computation to simulate high-stress events in arbitrarily large crowds of computer agents, but are unable to accurately model humans. Shared online virtual worlds provide a unique opportunity to conduct experiments with real humans in controlled settings. While experiments with human subjects in the real world offer the closest possible parallel to reality, these experiments are limited in number of subjects and the extent of stress that we can induce on the participants. However, by leveraging combinations of all 3 paradigms, we are uniquely positioned to evaluate our models and technologies in a rigorous manner. 


\begin{wrapfigure}{R}{0.30\textwidth} \vspace{-3mm}
	\centerline{\includegraphics[width=0.30\textwidth]{evaluation-plan.png}}
	\vspace{-3mm} \caption{\small Evaluation using Agent simulations, Shared Online Virtual Worlds, and Real World Experiments.}
	\label{fig1}
	\vspace{-3mm}
\end{wrapfigure}

\subsubsection{Simulation-based Evaluations: Agents. }

The first part of our efforts will focus on developing simulator for the two demonstration settings. Throughout the different phases of the project we will be capitalizing upon ? as well as augmenting the current capabilities of ? the SIDnet SWANS simulator [195] and SteerSuite: The Human Movement and Crowd Simulator [196], being developed at Northwestern and Rutgers respectively. SIDnet is used to evaluate various routing and tracking protocols, shapes detection, and even to evaluate the benefits of high-level programming constructs for WSN-users [113, 160, 187, 191]. SteerSuite is an open-source framework for simulating human movement, deliberation, and is especially geared towards dense crowd situations. We will integrate the functionality of these two systems and further augment them with the capability of having heterogeneous nodes and capturing various mobility models and communications between subsets of such nodes. In addition, we will augment its visualization component as well as introduce a new class of nodes with the proper interfaces to encode the following important features: (1) camera/video/audio based sensing and (2) human and human-operated sensors.  For the multimodal mashup scenario, we will simulate a simplified version of the ?Gold Miner? using computer imagery, with virtual objects and sensors. 
The main use of the simulator in the initial stages of the proposal will be to test the various impacts of uncertainty (sensors, network structure/communication) on the quality of detecting the novel categories of spatio-temporal predicates (cf. Section 3.4) and the impact of different policies for local state-estimation and information extraction (cf. Section 3.1 and 3.3). We will employ a large variety of crowd datasets to train and validate our computational models, and in particular leverage our collaboration with Prof. Dirk Helbing who has significant expertise in crowd data collection, analysis, and modeling [197].  In particular, we will integrate our simulation infrastructure with the NervousNet platform [198] that is being actively developed by Prof. Helbing and his colleagues as part of the larger effort on the Planetary Nervous System project [199], which provides a large-scale distributed research platform for real-time mining of social activities using heterogeneous sensor networks.


\subsubsection{Task E-2. Game Playing Evaluation: Avatars. }

Agent-based simulations, such as those described above provide an efficient way to test and evaluate the different aspects of our system in an automated fashion. However, in an effort to come closer to actual human experimentation, we will conduct experiments using real human users in shared online virtual environments. The Rutgers team is uniquely positioned to conduct these experiments ? Co-PI Kapadia has developed HeapCraft [200, 2001]: a modular, extensible, and open framework for studying human behavior in shared virtual worlds such as Minecraft. HeapCraft has already been successfully demonstrated to study player behavior and incentivize cooperation in online societies [202, 203]. Additionally, Kapadia and his collaborators have also conducted lab experiments to study crowd evacuations using serious games.
We will augment the existing HeapCraft framework to design the two scenarios described in Task E-3 below. HeapCraft?s modular and extensible nature allows us to easily develop emulators for the technologies being developed here, which can be rigorously and robustly tested in shared virtual worlds using real human users. In addition, we will augment the knowledge-base for emulating behavioral aspects of the avatars using large datasets of preferences and semantic relations from real social networks obtained from 4C Insights Inc. (Letter of Commitment is available in the Supplementary Documents). 
Our experiments will be conducted in two phases: (I) laboratory studies where up to 40 participants will be recruited to participate in a controlled experiment; (II) online server with our tools released to setup a virtual world with hundreds of human-users  expected to participate. 


\subsubsection{Task E-3. Real-World Environment Evaluations.  }

XX

